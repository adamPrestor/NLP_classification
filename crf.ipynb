{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T16:59:46.603535Z",
     "start_time": "2020-04-25T16:59:45.522846Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T16:59:49.497928Z",
     "start_time": "2020-04-25T16:59:49.123236Z"
    }
   },
   "outputs": [],
   "source": [
    "from preprocessing import read_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T16:59:50.161031Z",
     "start_time": "2020-04-25T16:59:50.067824Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>School</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Book ID</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Bookclub</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Message</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Message Time</th>\n",
       "      <th>Is Answer</th>\n",
       "      <th>Page</th>\n",
       "      <th>Book relevance</th>\n",
       "      <th>Type</th>\n",
       "      <th>Category</th>\n",
       "      <th>CategoryBroad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OŠ Ketteja in Murna</td>\n",
       "      <td>MumaD</td>\n",
       "      <td>8</td>\n",
       "      <td>Kako bi lahko Cefizelj pobegnil policistu še n...</td>\n",
       "      <td>Book Club One</td>\n",
       "      <td>1382</td>\n",
       "      <td>MumaD8</td>\n",
       "      <td>gremo se pogovarjati</td>\n",
       "      <td>Let's talk</td>\n",
       "      <td>2019-06-18 05:16:16 AM</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>S</td>\n",
       "      <td>CE</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OŠ Ketteja in Murna</td>\n",
       "      <td>MumaD</td>\n",
       "      <td>8</td>\n",
       "      <td>Kako bi lahko Cefizelj pobegnil policistu še n...</td>\n",
       "      <td>Book Club One</td>\n",
       "      <td>1392</td>\n",
       "      <td>MumaD18</td>\n",
       "      <td>Kip je to</td>\n",
       "      <td>This is a statue</td>\n",
       "      <td>2019-06-18 05:17:29 AM</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>S</td>\n",
       "      <td>CO</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OŠ Ketteja in Murna</td>\n",
       "      <td>MumaD</td>\n",
       "      <td>8</td>\n",
       "      <td>Kako bi lahko Cefizelj pobegnil policistu še n...</td>\n",
       "      <td>Book Club One</td>\n",
       "      <td>1392</td>\n",
       "      <td>MumaD18</td>\n",
       "      <td>Kdo je to jaz sem tara</td>\n",
       "      <td>Who is this I am Tara (girl's name)</td>\n",
       "      <td>2019-06-18 05:17:59 AM</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>Q</td>\n",
       "      <td>IQ</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OŠ Ketteja in Murna</td>\n",
       "      <td>MumaD</td>\n",
       "      <td>8</td>\n",
       "      <td>Kako bi lahko Cefizelj pobegnil policistu še n...</td>\n",
       "      <td>Book Club One</td>\n",
       "      <td>1382</td>\n",
       "      <td>MumaD8</td>\n",
       "      <td>kaj kip</td>\n",
       "      <td>what statue</td>\n",
       "      <td>2019-06-18 05:18:58 AM</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>S</td>\n",
       "      <td>CO</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OŠ Ketteja in Murna</td>\n",
       "      <td>MumaD</td>\n",
       "      <td>8</td>\n",
       "      <td>Kako bi lahko Cefizelj pobegnil policistu še n...</td>\n",
       "      <td>Book Club One</td>\n",
       "      <td>1382</td>\n",
       "      <td>MumaD8</td>\n",
       "      <td>gremo ven</td>\n",
       "      <td>let's go outside</td>\n",
       "      <td>2019-06-18 05:19:24 AM</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>S</td>\n",
       "      <td>CO</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                School Cohort  Book ID  \\\n",
       "0  OŠ Ketteja in Murna  MumaD        8   \n",
       "1  OŠ Ketteja in Murna  MumaD        8   \n",
       "2  OŠ Ketteja in Murna  MumaD        8   \n",
       "3  OŠ Ketteja in Murna  MumaD        8   \n",
       "4  OŠ Ketteja in Murna  MumaD        8   \n",
       "\n",
       "                                               Topic       Bookclub  User ID  \\\n",
       "0  Kako bi lahko Cefizelj pobegnil policistu še n...  Book Club One     1382   \n",
       "1  Kako bi lahko Cefizelj pobegnil policistu še n...  Book Club One     1392   \n",
       "2  Kako bi lahko Cefizelj pobegnil policistu še n...  Book Club One     1392   \n",
       "3  Kako bi lahko Cefizelj pobegnil policistu še n...  Book Club One     1382   \n",
       "4  Kako bi lahko Cefizelj pobegnil policistu še n...  Book Club One     1382   \n",
       "\n",
       "      Name                 Message                        Translation    \\\n",
       "0   MumaD8    gremo se pogovarjati                           Let's talk   \n",
       "1  MumaD18               Kip je to                     This is a statue   \n",
       "2  MumaD18  Kdo je to jaz sem tara  Who is this I am Tara (girl's name)   \n",
       "3   MumaD8                 kaj kip                          what statue   \n",
       "4   MumaD8               gremo ven                     let's go outside   \n",
       "\n",
       "             Message Time Is Answer  Page Book relevance Type Category  \\\n",
       "0  2019-06-18 05:16:16 AM        No     4             No    S       CE   \n",
       "1  2019-06-18 05:17:29 AM        No     4             No    S       CO   \n",
       "2  2019-06-18 05:17:59 AM        No     4             No    Q       IQ   \n",
       "3  2019-06-18 05:18:58 AM        No     4             No    S       CO   \n",
       "4  2019-06-18 05:19:24 AM        No     4             No    S       CO   \n",
       "\n",
       "  CategoryBroad  \n",
       "0             C  \n",
       "1             C  \n",
       "2             I  \n",
       "3             C  \n",
       "4             C  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "dataset_path = 'data/discussion_data.csv'\n",
    "df = read_dataset(dataset_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T16:59:53.185164Z",
     "start_time": "2020-04-25T16:59:53.117526Z"
    }
   },
   "outputs": [],
   "source": [
    "from preprocessing import Tokenization, StopWordsRemover, Lemmatization, RoofRemoval, SpellingCorrection\n",
    "from preprocessing import GibberishDetector, TokenGrouping, TokenDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T17:00:03.047422Z",
     "start_time": "2020-04-25T16:59:54.203422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct good: 1.0\n",
      "Correct bad: 1.0\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenization()\n",
    "stop_words_remover = StopWordsRemover('data/stopwords-sl-custom.txt')\n",
    "lemmatizer = Lemmatization()\n",
    "\n",
    "roof_removal = RoofRemoval()\n",
    "spelling_correction = SpellingCorrection('data/dict-sl.txt', roof_removal)\n",
    "\n",
    "gibberish_detector = GibberishDetector(roof_removal)\n",
    "# Train gibberish_detector\n",
    "gibberish_detector.train('data/dict-sl.txt', 'data/gibberish_good.txt', 'data/gibberish_bad.txt')\n",
    "\n",
    "token_grouping = TokenGrouping(gibberish_detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T17:00:03.893109Z",
     "start_time": "2020-04-25T17:00:03.651611Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "messages = df.Message\n",
    "messages = [tokenizer.tokenize(message) for message in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T17:00:04.534308Z",
     "start_time": "2020-04-25T17:00:04.489211Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "messages = [stop_words_remover.remove_stopwords(tokens) for tokens in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T17:00:05.190236Z",
     "start_time": "2020-04-25T17:00:05.138635Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "messages = [[lemmatizer.lemmatize(token) for token in message] for message in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T17:00:05.825583Z",
     "start_time": "2020-04-25T17:00:05.782051Z"
    }
   },
   "outputs": [],
   "source": [
    "# Roof removal\n",
    "messages = [[roof_removal.remove(token) for token in message] for message in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T17:00:06.423456Z",
     "start_time": "2020-04-25T17:00:06.390418Z"
    }
   },
   "outputs": [],
   "source": [
    "# Spelling correction\n",
    "# conversations = [[spelling_correction.replace_if_close(token) for token in tokens] for tokens in tqdm(conversations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T17:00:07.370713Z",
     "start_time": "2020-04-25T17:00:07.198244Z"
    }
   },
   "outputs": [],
   "source": [
    "# Token grouping\n",
    "messages = [[token_grouping.group_tokens(token) for token in message] for message in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T17:00:07.989202Z",
     "start_time": "2020-04-25T17:00:07.908100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create BoW dictionary\n",
    "token_dict = TokenDictionary(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T17:00:11.098177Z",
     "start_time": "2020-04-25T17:00:10.964399Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get tf-idf weighted BoW representations\n",
    "bow = np.stack([token_dict.bag_of_words(message, tf_idf=True) for message in messages])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = df.groupby(by=['School', 'Topic', 'Bookclub'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of conversations\n",
    "conversation_list = []\n",
    "for conversation in conversations.groups.keys():\n",
    "    conversation_df = conversations.get_group(conversation)\n",
    "    \n",
    "    conversation_el = [(row['Message'], row['CategoryBroad']) for _, row in conversation_df.iterrows()]\n",
    "    conversation_list.append(conversation_el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conversation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Skoka', 'D'),\n",
       " ('Jaz sem že brala ta zgodba', 'C'),\n",
       " ('Jst tut', 'C'),\n",
       " ('piši pravilno prosim!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!',\n",
       "  'C'),\n",
       " ('Kako lepo zgodbo!!!!!!!! Ta mi je tudi zelo všeč.', 'C'),\n",
       " ('Zadnja uprašanja so nemogoča!', 'C'),\n",
       " ('Pa lahko bi se naučil peti pesmice in pripovedovati zgodbice...', 'D'),\n",
       " ('Poleg tega pa sem tudi jaz že bral to zgodbo.', 'C'),\n",
       " ('Ali kdo v tem razredu sploh zna rešiti zadnje vprašanje? Kar koli napišem je narobe!',\n",
       "  'D'),\n",
       " ('Ja jaz tudi...', 'C'),\n",
       " ('Ali res alojzija 19! kako!?', 'D')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_list[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRF training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pycrfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define feature functions\n",
    "def get_features(messages, idx):\n",
    "    message = messages[idx]\n",
    "\n",
    "    feature_list = []\n",
    "    \n",
    "    count = len(message.split())\n",
    "    feature_list.append(f'length={count}')\n",
    "    \n",
    "    # TODO: features\n",
    "    \n",
    "    return feature_list\n",
    "\n",
    "def conversation2features(conversation):\n",
    "    messages = [message for message, _ in conversation]\n",
    "    features = [get_features(messages, i) for i in range(len(conversation))]\n",
    "    \n",
    "    return features\n",
    "    \n",
    "def conversation2labels(conversation):\n",
    "    labels = [label for _, label in conversation]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Prepare data for training (and testing if needed)\n",
    "random.shuffle(conversation_list)\n",
    "n_test_samples = int(0.2 * len(conversation_list))\n",
    "train_data = conversation_list[:-n_test_samples]\n",
    "test_data = conversation_list[-n_test_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [conversation2features(s) for s in train_data]\n",
    "y_train = [conversation2labels(s) for s in train_data]\n",
    "\n",
    "X_test = [conversation2features(s) for s in test_data]\n",
    "y_test = [conversation2labels(s) for s in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['length=8'],\n",
       " ['length=3'],\n",
       " ['length=5'],\n",
       " ['length=4'],\n",
       " ['length=2'],\n",
       " ['length=1'],\n",
       " ['length=7'],\n",
       " ['length=4'],\n",
       " ['length=1'],\n",
       " ['length=2'],\n",
       " ['length=1'],\n",
       " ['length=3']]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.67 ms, sys: 253 µs, total: 6.93 ms\n",
      "Wall time: 7.63 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 4. Prepare trainer\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 65.2 ms, sys: 3.37 ms, total: 68.5 ms\n",
      "Wall time: 74.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 4. Train a classifier (built classifier will be stored into a file \"model.crf.tagger\")\n",
    "trainer.train('discussions.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 50,\n",
       " 'scores': {},\n",
       " 'loss': 2948.72976,\n",
       " 'feature_norm': 9.767975,\n",
       " 'error_norm': 5.972897,\n",
       " 'active_features': 88,\n",
       " 'linesearch_trials': 1,\n",
       " 'linesearch_step': 1.0,\n",
       " 'time': 0.001}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.logparser.last_iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x11ceb0690>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('discussions.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: da si ni šel v nedeljo ogledat policaja\n",
      "D: Pobegnil bi policaju\n",
      "I: kdo si ti mi movej\n",
      "D: a ni policaj neumen\n",
      "C: kaj delaš\n",
      "I: lara\n",
      "M: Tukaj vaša učiteljica, prosim odgovorite na vprašanje.\n",
      "C: sram naj te modi\n",
      "C: lara\n",
      "C: nisi prijazna\n",
      "O: kijuhz\n",
      "C: ja res je\n",
      "Predicted: D D D D D D D D C C C C\n",
      "Correct:   D D I D C I M C C C O C\n"
     ]
    }
   ],
   "source": [
    "example_convo = train_data[0]\n",
    "for message, cls in example_convo:\n",
    "    print(f'{cls}: {message}')\n",
    "\n",
    "print(\"Predicted:\", ' '.join(tagger.tag(conversation2features(example_convo))))\n",
    "print(\"Correct:  \", ' '.join(conversation2labels(example_convo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "notify_time": "30",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "103px",
    "width": "220px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "501.85px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
